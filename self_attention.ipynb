{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7751070f-b568-467d-ba35-f771684c9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4ec398-172b-489d-ad70-99c4775bf6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_str = \"\"\"\n",
    "A transformer is a passive component that transfers electrical energy from one electrical circuit to another circuit, or multiple circuits. A varying current in any coil of the transformer produces a varying magnetic flux in the transformer's core, which induces a varying electromotive force (EMF) across any other coils wound around the same core. Electrical energy can be transferred between separate coils without a metallic (conductive) connection between the two circuits. Faraday's law of induction, discovered in 1831, describes the induced voltage effect in any coil due to a changing magnetic flux encircled by the coil.\n",
    "\n",
    "Transformers are used to change AC voltage levels, such transformers being termed step-up or step-down type to increase or decrease voltage level, respectively. Transformers can also be used to provide galvanic isolation between circuits as well as to couple stages of signal-processing circuits. Since the invention of the first constant-potential transformer in 1885, transformers have become essential for the transmission, distribution, and utilization of alternating current electric power.[1] A wide range of transformer designs is encountered in electronic and electric power applications. Transformers range in size from RF transformers less than a cubic centimeter in volume, to units weighing hundreds of tons used to interconnect the power grid.\n",
    "\"\"\"\n",
    "\n",
    "# Clean dataset\n",
    "data = data_str.replace(\"\\n\", \"\").split(\" \")\n",
    "\n",
    "# Create embedding dictionary\n",
    "unique_data = list(set(data))\n",
    "n_embedding = len(unique_data)\n",
    "emb_dict = dict([(val, i) for i, val in enumerate(unique_data)])\n",
    "\n",
    "# No. of unique words\n",
    "n_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0860803-af59-4f53-96f3-84cd6f36f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionWithEmbedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_init, n_embedding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = np.sqrt(n_init)\n",
    "        \n",
    "        self.Embedding = torch.nn.Embedding(n_embedding, n_init)\n",
    "        \n",
    "        self.Q = torch.nn.Linear(n_init, n_init)\n",
    "        self.K = torch.nn.Linear(n_init, n_init)\n",
    "        self.V = torch.nn.Linear(n_init, n_init)\n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        self.output = torch.nn.Linear(n_init**2, n_embedding)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_emb = self.Embedding(x)\n",
    "        \n",
    "        x_q = self.Q(x_emb)\n",
    "        x_k = self.K(x_emb)\n",
    "        x_v = self.V(x_emb)\n",
    "\n",
    "        x_k_t = torch.transpose(x_k, 1, 2)\n",
    "        \n",
    "        output = self.softmax(torch.matmul(x_q, x_k_t) / self.scale)\n",
    "        output = torch.matmul(output, x_v)\n",
    "        output = torch.flatten(output, start_dim=1)\n",
    "\n",
    "        output = self.output(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "394293de-eef7-4436-9579-7168a2a4ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, n_seq=12):\n",
    "\n",
    "    data_clear = data.replace(\"\\n\", \"\").split(\" \")\n",
    "    unique_data = list(set(data_clear))\n",
    "    n_embedding = len(unique_data)\n",
    "    emb_dict = dict([(val, i) for i, val in enumerate(unique_data)])\n",
    "    data_emb = [emb_dict[i] for i in data_clear]\n",
    "    \n",
    "    dataset_emb = np.array([[k for k in data_emb[i:(i+12)]] for i in range(len(data_emb) - n_seq - 1)])\n",
    "    y = [d[-1] for d in dataset_emb[1:]]\n",
    "    \n",
    "    x = torch.from_numpy(np.array(dataset_emb[:-1]))\n",
    "    y = torch.from_numpy(np.array(y, dtype='int64'))\n",
    "    y_onehot = torch.nn.functional.one_hot(y, num_classes=n_embedding).type(torch.DoubleTensor)\n",
    "    \n",
    "    \n",
    "    return torch.utils.data.TensorDataset(x, y_onehot)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d00664-f9ab-4170-aeb9-c03856314ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3052, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(185)\n",
      "tensor(0.3011, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(184)\n",
      "tensor(0.2979, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(180)\n",
      "tensor(0.2945, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(176)\n",
      "tensor(0.2911, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(175)\n",
      "tensor(0.2877, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(173)\n",
      "tensor(0.2839, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(175)\n",
      "tensor(0.2798, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(171)\n",
      "tensor(0.2757, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(171)\n",
      "tensor(0.2713, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(171)\n",
      "tensor(0.2663, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(172)\n",
      "tensor(0.2614, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(172)\n",
      "tensor(0.2559, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(171)\n",
      "tensor(0.2504, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(171)\n",
      "tensor(0.2440, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(169)\n",
      "tensor(0.2368, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(168)\n",
      "tensor(0.2290, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(162)\n",
      "tensor(0.2201, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(160)\n",
      "tensor(0.2103, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(154)\n",
      "tensor(0.1989, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(145)\n",
      "tensor(0.1865, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(125)\n",
      "tensor(0.1731, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(107)\n",
      "tensor(0.1583, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(88)\n",
      "tensor(0.1434, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(65)\n",
      "tensor(0.1288, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(48)\n",
      "tensor(0.1133, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(35)\n",
      "tensor(0.0996, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(29)\n",
      "tensor(0.0861, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(26)\n",
      "tensor(0.0747, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(23)\n",
      "tensor(0.0647, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(16)\n",
      "tensor(0.0561, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(14)\n",
      "tensor(0.0485, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(12)\n",
      "tensor(0.0424, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(8)\n",
      "tensor(0.0371, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(6)\n",
      "tensor(0.0328, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(4)\n",
      "tensor(0.0290, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(4)\n",
      "tensor(0.0257, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(4)\n",
      "tensor(0.0229, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(3)\n",
      "tensor(0.0207, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0183, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0166, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0151, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0136, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0113, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0104, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0095, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(1)\n",
      "tensor(0.0088, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0081, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0076, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0070, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0066, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0061, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0057, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0054, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0051, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0049, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0046, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0043, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0040, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0039, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0037, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0035, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0034, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0032, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0030, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0029, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0028, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0027, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0025, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0024, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0023, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0022, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0021, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0020, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0020, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0019, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0018, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0017, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0016, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0016, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0015, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0015, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0014, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0013, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0013, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0012, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0011, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<DivBackward0>) errors: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# Create self attention layer with embeddings\n",
    "layer = SelfAttentionWithEmbedding(12,  # Input sequence length\n",
    "                                   n_embedding  # Embedding layer output no. dimensions & layer output no. dimensions\n",
    "                                  )\n",
    "\n",
    "# Create dataset from string data\n",
    "dataset = create_dataset(data_str)\n",
    "\n",
    "# Create pytorch model\n",
    "model = torch.nn.Sequential()\n",
    "model.add_module('fc1', layer)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train for 100 epochs\n",
    "for t in range(100):\n",
    "\n",
    "    # Loss per epoch & no. of errors\n",
    "    epoch_loss = 0\n",
    "    errors = 0\n",
    "\n",
    "    # For every batch\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        # Make predictions with the current parameters\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # Compute the loss value.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Add loss divided by number of samples per batch\n",
    "        epoch_loss += torch.sum(loss) / 16\n",
    "        \n",
    "        # Add number or wrong predicted words\n",
    "        errors += torch.sum(torch.argmax(y_pred, dim=1) != torch.argmax(y, dim=1))\n",
    "        \n",
    "        # Update the model's parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss and errors per epoch\n",
    "    print(epoch_loss / (batch_idx + 1), 'errors:', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f35f1f-cac7-439b-b80f-e82d1f51be00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([0.9950, 0.9938, 0.9935, 0.9835, 0.9935, 0.9812, 0.9891, 0.9895, 0.9902,\n",
       "         0.9532, 0.9544, 0.9955, 0.9760], grad_fn=<MaxBackward0>),\n",
       " indices=tensor([ 45, 112,  46, 125, 115,  83, 104,  77,  61,  74, 127, 129, 117])),\n",
       " tensor([ 45, 112,  46, 125, 115,  83, 104,  77,  61,  74, 127, 129, 117]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print max values of model's predictions and targer for one batch \n",
    "torch.max(model[0].softmax(model(x)), dim=1), torch.argmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ff0d935-b086-433b-8cca-40b93c88861d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 49, 127,  44,  74, 127, 105,  13,  90,  70,  82,  93,  56],\n",
       "        dtype=torch.int32),\n",
       " tensor(45))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single traing sample and label\n",
    "x[0], torch.argmax(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91c00a-7cda-49b2-8bb0-de3a49fabbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
